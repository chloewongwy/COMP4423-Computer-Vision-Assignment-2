# -*- coding: utf-8 -*-
"""ResNetvsVGG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K6n9T-UkKz-XsWdS_ZfwcdraFgqxHqRA
"""

# Task 1: ResNet vs VGG

# --- Imports libraries ---
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
import matplotlib.pyplot as plt
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import loss_landscapes


# --- Load device ---
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("Using device:", device)

# --- Load CIFAR-10 training set (resized to fit VGG/ResNet) ---
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True)

# --- Load pretrained VGG16 and ResNet18 and adapt for CIFAR-10 ---
# VGG16
vgg16 = models.vgg16(pretrained=True)
vgg16.classifier[6] = nn.Linear(4096, 10)
vgg16 = vgg16.to(device)
vgg16.eval()

# ResNet18
resnet18 = models.resnet18(pretrained=True)
resnet18.fc = nn.Linear(resnet18.fc.in_features, 10)
resnet18 = resnet18.to(device)
resnet18.eval()

# --- Loss function ---
criterion = nn.CrossEntropyLoss()

# --- Attach evaluate_batch directly to model ---
def attach_evaluate_batch(model, criterion, inputs, labels):
    def evaluate_batch(_):
        outputs = model(inputs)
        return criterion(outputs, labels)
    model.evaluate_batch = evaluate_batch

# --- Loss landscape plotting function ---
def plot_loss_landscape(model, model_name):
    model.eval()

    # Get one batch
    images, labels = next(iter(trainloader))
    images, labels = images.to(device), labels.to(device)

    # Wrap the model
    attach_evaluate_batch(model, criterion, images, labels)

    # Generate the surface
    surface = loss_landscapes.random_plane(
        model,
        model.evaluate_batch,
        distance=0.5,
        steps=20,
        normalization='filter'
    )

    # Manual 3D plot
    X = np.linspace(-0.5, 0.5, surface.shape[0])
    Y = np.linspace(-0.5, 0.5, surface.shape[1])
    X, Y = np.meshgrid(X, Y)
    Z = surface

    fig = plt.figure(figsize=(10, 7))
    ax = fig.add_subplot(111, projection='3d')
    ax.plot_surface(X, Y, Z, cmap='viridis')
    ax.set_title(f"Loss Landscape: {model_name}")
    ax.set_xlabel("Direction 1")
    ax.set_ylabel("Direction 2")
    ax.set_zlabel("Loss")
    plt.tight_layout()
    plt.savefig(f"{model_name}_loss_landscape.png")
    plt.show()

# --- Generate and show loss landscape visualizations ---
plot_loss_landscape(vgg16, "VGG16")
plot_loss_landscape(resnet18, "ResNet18")

# --- Average gradients per layer function ---
def plot_gradient_flow(model, model_name):
    model.train()

    images, labels = next(iter(trainloader))
    images, labels = images.to(device), labels.to(device)

    optimizer = optim.SGD(model.parameters(), lr=0.01)
    optimizer.zero_grad()
    outputs = model(images)
    loss = criterion(outputs, labels)
    loss.backward()

    ave_grads = []
    layers = []

    for name, param in model.named_parameters():
        if param.requires_grad and "weight" in name and param.grad is not None:
            layers.append(name)
            ave_grads.append(param.grad.abs().mean().item())

    plt.figure(figsize=(10, 5))
    plt.plot(ave_grads, alpha=0.3, color="b")
    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color="k")
    plt.xticks(range(len(ave_grads)), layers, rotation='vertical')
    plt.xlabel("Layers")
    plt.ylabel("Average Gradient")
    plt.title(f"Gradient Flow: {model_name}")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(f"{model_name}_gradient_flow.png")
    plt.show()

# --- Generate gradient flow plots ---
plot_gradient_flow(vgg16, "VGG16")
plot_gradient_flow(resnet18, "ResNet18")